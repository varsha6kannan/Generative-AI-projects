{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PDF RAG SEARCH WITH OLLAMA AND CREWAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to install ollama\n",
    "1. url->https://ollama.com/download download the ollama setup from here and execute the installation\n",
    "2. ollama pull phi3:3.8b -> pulling the open ai model, which has been trained on 3.8 parameters\n",
    "3. check if ollama server is up and running by visiting this url-> http://localhost:11434/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input used for this model is a research paper on deepseek-> \"DeepSeek-VL: Towards Real-World Vision-Language\n",
    "Understanding\" \n",
    "- url of pdf -> https://arxiv.org/abs/2403.05525\n",
    "- github link- https://github.com/ollama/ollama\n",
    "- more on installation of ollama https://www.youtube.com/watch?v=UtSSMs6ObqY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STEP 1: Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from crewai import Agent,Task,Crew\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STEP 2: Giving a dummy api key as the OpenAI chat has a placeholder for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=\"sk-proj-1234\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STEP3: Let's define the ollama LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model='ollama/phi3:latest',\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"sk-proj-1234\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STEP 4: Let's define the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embedchain import App\n",
    "from embedchain.embedder.ollama import OllamaEmbedder\n",
    "from crewai_tools.tools.pdf_search_tool.pdf_search_tool import PDFSearchTool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now since we are using a local AI model ollama, crew uses embedchain to perform RAG searches, so we to use ollama \n",
    "- for embedding\n",
    "- for query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Varsha Kannan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\embedchain\\embedder\\ollama.py:27: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings = OllamaEmbeddings(model=self.config.model, base_url=config.base_url)\n",
      "Inserting batches in chromadb:   0%|          | 0/2 [00:00<?, ?it/s]2025-01-31 17:53:28,248 - 22308 - local_persistent_hnsw.py-local_persistent_hnsw:339 - WARNING: Add of existing embedding ID: default-app-id--570d4af502dda016548c1c6cf5eb3550c4a9e59c373251008761ed7e3a790beb\n",
      "2025-01-31 17:53:28,248 - 22308 - local_persistent_hnsw.py-local_persistent_hnsw:339 - WARNING: Add of existing embedding ID: default-app-id--570d4af502dda016548c1c6cf5eb3550c4a9e59c373251008761ed7e3a790beb\n",
      "2025-01-31 17:53:28,248 - 22308 - local_persistent_hnsw.py-local_persistent_hnsw:339 - WARNING: Add of existing embedding ID: default-app-id--570d4af502dda016548c1c6cf5eb3550c4a9e59c373251008761ed7e3a790beb\n",
      "Inserting batches in chromadb:   0%|          | 0/2 [03:57<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF added successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from embedchain import App\n",
    "from embedchain.models.data_type import DataType  # Import the correct data type\n",
    "\n",
    "# Set the Ollama host (if needed)\n",
    "os.environ[\"OLLAMA_HOST\"] = \"http://127.0.0.1:11434\"\n",
    "\n",
    "# Load embedding model configuration from config.yaml file\n",
    "app = App.from_config(config_path=\"config.yaml\")\n",
    "\n",
    "# Provide the correct PDF file path\n",
    "pdf_path = r\"D:\\Courses\\Crew AI youtube crash course\\deepseek.pdf\"  # Ensure the file exists\n",
    "\n",
    "# Use the correct enum for data_type\n",
    "app.add(pdf_path, data_type=DataType.PDF_FILE)\n",
    "\n",
    "print(\"PDF added successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the PDF RAG Search Tool with Ollama\n",
    "pdf_rag_tool = PDFSearchTool(app=app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STEP 5: Let's define the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, Process\n",
    "\n",
    "researcher=Agent(\n",
    "    role=\"Information Agent\",\n",
    "    goal=\"Go through the query asked on the topic {topic}, and retrieve all the relevent content about the topic and write it down\",\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    memory=True,\n",
    "    backstory=\"\"\"\n",
    "        You are an expert in going through pdfs and understanding the content and writing a short summary about it.\n",
    "    \"\"\",\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "writer=Agent(\n",
    "    role=\"Content writer\",\n",
    "    goal=\"Go through the content {topic} provided by the researcher agent and summarize and give the answer in consice and meaningful format\",\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    memory=True,\n",
    "    backstory=\"\"\"You are exceptional in explaining complex topics in simple words in the form of bullet points\"\"\",\n",
    "    llm=llm,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STEP 6: Define the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_task = Task(\n",
    "    description=\"Search and collect information on {topic}.\",\n",
    "    expected_output=\"Colect all the information about {topic} and write in the form 1 paragraph.\",\n",
    "    agent=researcher\n",
    ")\n",
    "\n",
    "write_task=Task(\n",
    "    description=\"Bullet points on {topic}.\",\n",
    "    expected_output=\"Write short consice bullet points of main points one below the other, in less than 30 words. \",\n",
    "    agent=writer,\n",
    "    async_execution=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "crew = Crew(\n",
    "    agents=[researcher,writer],\n",
    "    tasks=[research_task,write_task],\n",
    "    verbose=True,\n",
    "    tools=[pdf_rag_tool],\n",
    "    process=Process.sequential\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mInformation Agent\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mSearch and collect information on Explain the performance of deepseek..\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mInformation Agent\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "DeepSeek's performance has demonstrated remarkable efficiency in processing large datasets within short timeframes due to its innovative architecture which utilizes parallel computing techniques. Studies have shown that when tasked with complex data retrieval operations, the system can outperform traditional search methods by significant margins, often reducing latency and increasing throughput rates. This is attributed to DeepSeek's advanced indexing methodologies combined with machine learning algorithms for pattern recognition which expedite query resolution processes effectively. In various benchmark tests conducted across different industries ranging from financial services to academic research fields, the results consistently highlighted that deploying DeepSeek resulted in a notable reduction of time taken per search operation while maintaining high accuracy and relevancy standards set by industry experts as compared with its predecessors or competitors.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent writer\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mBullet points on Explain the performance of deepseek..\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent writer\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "âœ… Thoughts on DeepSeek's performance are concise below, respecting word limit constraints while encapsulating essence of its effectiveness in data processing tasks across industries compared to traditional methods due largely to innovative architecture and advanced indexing methodologies backed by machine learning for swift pattern recognition.\n",
      "\n",
      "- Efficiently processes large datasets quickly using parallel computing techniques. âœ…\n",
      "- Outperforms conventional search with reduced latency, higher throughput rates in complex data retrieval tasks; consistently exceeds industry standards of speed while maintaining accuracy and relevancy across various sectors including finance and research fields. âœ…\u001b[00m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = crew.kickoff(inputs={'topic':'Explain the performance of deepseek.'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
